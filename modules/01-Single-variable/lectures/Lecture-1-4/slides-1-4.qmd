---
title: "Data Analytics and Visualization"
subtitle: "1-4: Maximum Likelihood and Clustering"
author: "Prof. Gabe Hope"
format: 
    revealjs:
        theme: ["../../../../theme.scss"]
        html-math-method: katex
        slideNumber: true
---

## Wind vectors

::::: columns
::: {.column style="width: 50%"}

```{ojs}
tf = require('@tensorflow/tfjs@4.11.0')
d3Fetch = require("d3-fetch@1.1.2")
tquantile = import('https://cdn.jsdelivr.net/gh/stdlib-js/stats-base-dists-t-quantile@esm/index.mjs')

wind = FileAttachment("data/wind.csv").csv({typed: true})
land = topojson.feature(europe, europe.objects.europe)
europe = d3Fetch.json("https://raw.githubusercontent.com/leakyMirror/map-of-europe/master/TopoJSON/europe.topojson")
circle = d3.geoCircle().center([0, 52]).radius(5.5).precision(2)()

Plot.plot({
  width: 500,
  height: 500,
  inset:  10,
  aspectRatio: 1,
  color: {
    label: "Speed (m/s)",
    zero: true,
    legend: true
  },
  projection: {
    type: "azimuthal-equal-area",
    //rotate: [-9, -34],
    domain: circle,
    inset: 10
  },
  marks: [
    Plot.graticule(),
    Plot.geo(land, {fill: "currentColor", stroke: 'black', fill: 'white'}),
    Plot.vector(wind, {
      x: "longitude",
      y: "latitude",
      rotate: ({u, v}) => Math.atan2(u, v) * 180 / Math.PI,
      length: ({u, v}) => Math.hypot(u, v),
      stroke: ({u, v}) => Math.hypot(u, v)
    }),    
  ]
})
```
:::
::: {.column style="width: 50%; font-size: 75%"}

We'll focus on just the `speed` variable.
```{ojs}

data2 = d3Fetch.csv("https://raw.githubusercontent.com/vega/vega-datasets/master/data/windvectors.csv");
windpopulation = tf.tensor(data2.map(d => parseFloat(d['speed']))).reshape([-1, 1]);


Plot.plot({
  height: 500,
  width: 500,
  x: {label: "Wind speed (m/s)", domain: tf.tidy(() => {return [windpopulation.min().arraySync(), windpopulation.max().arraySync()]})},
  marks: [
    Plot.dot(windpopulation.arraySync(), Plot.dodgeY({x: "0", r:1.5, fill: '0'})),
  ]
})
```
:::
:::::

## IMDB Ratings

User ratings for movies on IMDB.
```{ojs}

//data2 = d3Fetch.csv("https://raw.githubusercontent.com/vega/vega-datasets/master/data/windvectors.csv");
//population = tf.tensor(data2.map(d => parseFloat(d['speed']))).reshape([-1, 1]);

imdb = { 
  let data = await d3Fetch.json("https://raw.githubusercontent.com/vega/vega-datasets/master/data/movies.json");
  return data.map((d) => {
    d["Major Genre"] = d["Major Genre"] || "Unclassified";
    return d;
  });
};
imdbpopulation = tf.tensor(imdb.map(d => parseFloat(d['IMDB Rating'])).filter((d) => d == d)).reshape([-1, 1]);

Plot.plot({
  height: 500,
  width: 1000,
  x: {label: "IMDB Rating", domain: tf.tidy(() => {return [imdbpopulation.min().arraySync(), imdbpopulation.max().arraySync()]})},
  color: {legend: true},
  marks: [
    Plot.dot(imdb, Plot.dodgeY({x: "IMDB Rating", r:1.5, tip: true, title: "Title", fill: "Major Genre"})),
  ]
})
```

## Setup

```{python}
#| echo: true

import pandas as pd
import numpy as np
from lets_plot import *
LetsPlot.setup_html()
import vega_datasets

imdb = vega_datasets.data.movies()
wind = vega_datasets.data.windvectors()
```

## Fitting a Normal model

Estimate the parameters:
```{python}
#| echo: true
from scipy.stats import norm
imdb_model = norm(imdb['IMDB_Rating'].mean(), imdb['IMDB_Rating'].std())
```
Plot the distribution

```{python}
#| echo: true
x = np.linspace(0, 12, 1000)
est_pdf = imdb_model.pdf(x)
pdf_data = pd.DataFrame(dict(x=x, y=est_pdf))
ggplot() + geom_dotplot(data=imdb, 
  mapping=aes(x='IMDB_Rating'), color='#4682b4', binwidth=0.04)\
 + geom_line(data= pdf_data, mapping=aes(x='x', y='y'), color='red')\
   + ggsize(1000, 300)
```

## Checking the fit

Plot empirical CDF against estimated CDF

```{python}
#| echo: true
x = np.linspace(0, 12, 1000)
est_cdf = imdb_model.cdf(x)
model_data = pd.DataFrame(dict(x=x, y=est_cdf))
ggplot(imdb, aes(x='IMDB_Rating')) + stat_ecdf() + geom_line(data=model_data, mapping=aes(x='x', y='y'), color='red') + ggsize(1000, 400)
```

## Quantile-quantile plots

Plot empirical quantiles against estimated quantiles

:::: columns
::: {.column style="width: 50%"}


:::
::: {.column style="width: 50%; font-size: 65%"}

```{python}
#| echo: true
x = np.linspace(0, 1, 100)
emp_quantile = imdb['IMDB_Rating'].quantile(x)
the_quantile = imdb_model.ppf(x)
qq_data = pd.DataFrame(dict(
  empirical= emp_quantile, 
  theoretical=the_quantile))
ggplot() + geom_abline(slope=1)\
   + geom_point(
    data=qq_data, 
    mapping=aes(x='empirical', y='theoretical')
  )\
      + coord_fixed()
```
:::
::::

# What about the wind data?

## What about the wind data?
Estimate the parameters:
```{python}
#| echo: true
wind_model = norm(wind['speed'].mean(), wind['speed'].std())
```

Plot the distribution
```{python}
#| echo: true
x = np.linspace(0, 12, 1000)
est_pdf = wind_model.pdf(x)
pdf_data = pd.DataFrame(dict(x=x, y=est_pdf))
ggplot() + geom_dotplot(data=wind, mapping=aes(x='speed'), color='#4682b4', binwidth=0.05) + geom_line(data= pdf_data, mapping=aes(x='x', y='y'), stroke='red') + ggsize(1000, 300)
```

## Checking the fit

```{python}
#| echo: true
x = np.linspace(0, 12, 1000)
est_cdf = wind_model.cdf(x)
model_data = pd.DataFrame(dict(x=x, y=est_cdf))
ggplot(wind, aes(x='speed')) + stat_ecdf() + geom_line(data=model_data, mapping=aes(x='x', y='y'), color='red') + ggsize(1000, 400)
```

## QQ-Plot
Plot empirical quantiles against estimated quantiles

:::: columns
::: {.column style="width: 50%"}


:::
::: {.column style="width: 50%; font-size: 65%"}

```{python}
#| echo: true
x = np.linspace(0, 1, 100)
emp_quantile = wind['speed'].quantile(x)
the_quantile = wind_model.ppf(x)
qq_data = pd.DataFrame(dict(
  empirical= emp_quantile, 
  theoretical=the_quantile))
ggplot() + geom_abline(slope=1)\
   + geom_point(
    data=qq_data, 
    mapping=aes(x='empirical', y='theoretical')
  )\
      + coord_fixed()
```
:::
::::

## What would be better? 

Looks more like 2 normals!

```{python}
#| echo: false
x = np.linspace(0, 12, 1000)
est_pdf = wind_model.pdf(x)
pdf_data = pd.DataFrame(dict(x=x, y=est_pdf))
ggplot() + geom_dotplot(data=wind, mapping=aes(x='speed'), color='#4682b4', binwidth=0.05) + geom_line(data= pdf_data, mapping=aes(x='x', y='y'), stroke='red') + ggsize(1000, 300)
```

## Shorthand notation

Normal PDF
$$x \sim \mathcal{N}(x; \mu, \sigma) \qquad p(x) = \phi(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2}$$


## Mixture of 2 Normals distribution

:::: columns
::: {.column style="width: 50%; font-size: 65%"}
Mixture of 2 Normals
$$p(x) = p_1 \phi(x; \mu_1, \sigma_1) +  p_2 \phi(x; \mu_2, \sigma_2)$$

Still a distribution!
$$p_1 \geq 0,\ p_2 \geq 0, \quad p_1 + p_2 = 1$$

$$\therefore \quad \int_{-\infty}^\infty p(x) dx = 1$$

:::
::: {.column style="width: 50%; font-size: 65%"}
```{=html}
<iframe width="100%" height="689" frameborder="0"
  src="https://observablehq.com/embed/d43295df058719a9@145?cells=viewof+p%2Cviewof+m1%2Cviewof+m2%2Cviewof+s1%2Cviewof+s2%2Cviewof+mplot"></iframe>
```
:::
::::


## Remember:

$$x \sim \mathcal{N}(x; \mu, \sigma) \qquad p(x) = \phi(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2}$$

So mixture pdf also can be written explicitly:

$$p(x) = p_1 \cdot \frac{1}{\sigma_1 \sqrt{2 \pi}} e^{-\frac{1}{2}\left( \frac{x-\mu_1}{\sigma_1} \right)^2} +  p_2 \cdot \frac{1}{\sigma_2 \sqrt{2 \pi}} e^{-\frac{1}{2}\left( \frac{x-\mu_2}{\sigma_2} \right)^2}$$



## In code

:::: columns
::: {.column style="width: 50%; font-size: 65%"}
Mixture of 2 Normals pdf:
$$p(x) = p_1 \phi(x; \mu_1, \sigma_1) +  p_2 \phi(x; \mu_2, \sigma_2)$$

#### CDF

Let 

$$\Phi(x; \mu, \sigma) = \int_{-\infty}^x \phi(y; \mu, \sigma) dy$$ 
be the Normal CDF function



The CDF of a mixture distribution can be written as:
$$F(x) =\sum_{k=1}^Kp_k \cdot \Phi(x; \mu_k, \sigma_k)$$

:::
::: {.column style="width: 50%; font-size: 65%"}
```{python}
#| echo: true
def pdf(x, p1, mu1, sigma1, mu2, sigma2):
    p2 = 1 - p1
    return p1 * norm(mu2, sigma2).pdf(x)\
       + p2 * norm(mu1, sigma1).pdf(x)

def cdf(x, p1, mu1, sigma1, mu2, sigma2):
    p2 = 1 - p1
    return p1 * norm(mu2, sigma2).cdf(x)\
       + p2 * norm(mu1, sigma1).cdf(x)
```
:::
::::

## Generalizes to K **components**

Mixture of $K$ Normals
$$p(x) =\sum_{k=1}^Kp_k \cdot \phi(x; \mu_k, \sigma_k) $$

$$p(x) =\sum_{k=1}^Kp_k \cdot \frac{1}{\sigma_k \sqrt{2 \pi}} e^{-\frac{1}{2}\left( \frac{x-\mu_k}{\sigma_k} \right)^2}$$

Looks like our Gaussian KDE!

$$\hat{p}(x) = \frac{1}{2Nh} \sum_{i=1}^N \phi\left(\frac{x - x_i}{h}\right), \quad \phi(u) = \frac{1}{\sqrt{2 \pi}} \exp\left(-\frac{u^2}{2} \right)$$

## Sampling from a mixture

:::: columns
::: {.column style="width: 50%; font-size: 65%"}
Introduce $z$
$$z\in \{1,...,K\}$$

$$p(z): \quad z \sim \text{Categorical}(p_1, p_2, ...,p_K)$$
$$p(Z=k) = p_k$$

$$p(x\mid z): \quad x \sim \mathcal{N}(x; \mu_z, \sigma_z)$$

$$p(x \mid z) = \phi(x; \mu_z, \sigma_z) $$
$$= \frac{1}{\sigma_{z} \sqrt{2 \pi}} \exp\left(-\frac{1}{2}\left( \frac{x-\mu_{z}}{\sigma_{z}} \right)^2\right)$$
:::
::: {.column style="width: 50%; font-size: 65%"}
```{=html}
<iframe width="100%" height="816" frameborder="0"
  src="https://observablehq.com/embed/d43295df058719a9@145?cells=viewof+p%2Cviewof+m1%2Cviewof+m2%2Cviewof+s1%2Cviewof+s2%2Cviewof+mplot%2Cviewof+replay%2Cviewof+takeSample%2Cviewof+reset"></iframe>
```
:::
::::

## Results

```{python}
#| echo: true
from sklearn.mixture import GaussianMixture

wind_model = GaussianMixture(n_components=2).fit(wind['speed'].values.reshape((-1, 1)))

x = np.linspace(0, 12, 1000)
est_pdf = np.exp(wind_model.score_samples(x.reshape((-1, 1))).reshape((-1,)))
pdf_data = pd.DataFrame(dict(x=x, y=est_pdf))

ggplot() + geom_dotplot(data=wind, mapping=aes(x='speed'), color='#4682b4', binwidth=0.05) + geom_line(data= pdf_data, mapping=aes(x='x', y='y'), stroke='red') + ggsize(1000, 400)
```


## Results

```{python}
#| echo: true
p1 = wind_model.weights_[0].item()
mu1 = wind_model.means_[0].item()
sigma1 = np.sqrt(wind_model.covariances_[0].item())
mu2 = wind_model.means_[1].item()
sigma2 = np.sqrt(wind_model.covariances_[1].item())

x = np.linspace(0, 12, 1000)
est_cdf = cdf(x, p1, mu1, sigma1, mu2, sigma2)
model_data = pd.DataFrame(dict(x=x, y=est_cdf))
ggplot(wind, aes(x='speed')) + stat_ecdf() + geom_line(data=model_data, mapping=aes(x='x', y='y'), color='red')+ ggsize(1000, 400)

```

## code: maximize

```{python}
#| echo: true
def maximize(x, z):
    mu1 = x[z == 0].mean()
    sigma1 = x[z == 0].std()

    mu2 = x[z == 1].mean()
    sigma2 = x[z == 1].std()

    p1 = (z == 0).mean()
    return p1, mu1, sigma1, mu2, sigma2
```

## code: assign

```{python}
#| echo: true
def assign(x, p1, mu1, sigma1, mu2, sigma2):
    p2 = 1. - p1
    p_x_given_1 = norm(mu1, sigma1).pdf(x)
    p_x_given_2 = norm(mu2, sigma2).pdf(x)

    p_x_and_1 = p_x_given_1 * p1
    p_x_and_2 = p_x_given_2 * p2

    p_1_given_x = p_x_and_1 / (p_x_and_1 + p_x_and_2)
    p_2_given_x = p_x_and_2 / (p_x_and_1 + p_x_and_2)
    
    return p_1_given_x < p_2_given_x
```

## code: EM
```{python}
#| echo: true
def em(x):
    params = maximize(x, x > 5)
    for _ in range(100):
        z = assign(x, *params)
        params = maximize(x, z)
    return params
```

## Expectation-Maximization algorithm

::: {style="font-size: 60%"}

**E-Step**

For all $i\in \{1,...,N\}$, $k\in \{1,...,K \}$ set:

$$w_{ik} = p(z_i=k \mid x_i)  =\frac{p_{k} \cdot \phi(x; \mu_{k}, \sigma_{k})}{ \sum_{c=1}^K p_c \cdot \phi(x; \mu_c, \sigma_c)} $$

**M-Step**

For all $k\in \{1,...,K \}$ set:

$$\mu_k = \frac{1}{\sum_{i=1}^N w_{ik}} \sum_{i=1}^N w_{ik} x_i$$
$$\sigma_k = \sqrt{\frac{1}{\sum_{i=1}^N w_{ik}} \sum_{i=1}^N w_{ik} (x_i - \mu_k)^2}$$
$$p_k = \frac{\sum_{i=1}^N w_{ik}}{N}$$

**Repeat!**
:::

## Code: K-Means
::: {style="font-size: 60%"}
```{python}
#| echo: true
def maximize(x, z):
    mu1 = x[z == 0].mean()
    mu2 = x[z == 1].mean()
    return mu1, mu2

def assign(x, mu1,  mu2):    
    return (x - mu1) ** 2 < (x - mu2) ** 2

def kmeans(x):
    params = maximize(x, x > 5)
    
    for _ in range(100):
        z = assign(x, *params)
        params = maximize(x, z)
    return params
```
:::

## Code: EM
::: {style="font-size: 60%"}
```{python}
#| echo: true
def maximize(x, w):
    w1, w2 = w
    mu1 = (w1 * x).sum() / w1.sum()
    sigma1 = np.sqrt((w1 * (x - mu1) ** 2 ).sum() / w1.sum())

    mu2 = (w2 * x).sum() / w1.sum()
    sigma2 = np.sqrt((w2 * (x - mu2) ** 2 ).sum() / w2.sum())

    p1 = w1.mean()
    return p1, mu1, sigma1, mu2, sigma2

def assign(x, p1, mu1, sigma1, mu2, sigma2):
    p2 = 1. - p1
    p_x_given_1 = norm(mu1, sigma1).pdf(x)
    p_x_given_2 = norm(mu2, sigma2).pdf(x)

    p_x_and_1 = p_x_given_1 * p1
    p_x_and_2 = p_x_given_2 * p2

    p_1_given_x = p_x_and_1 / (p_x_and_1 + p_x_and_2)
    p_2_given_x = p_x_and_2 / (p_x_and_1 + p_x_and_2)
    
    return p_1_given_x, p_2_given_x

def em(x):
    params = maximize(x, x > 5)
    for _ in range(100):
        z = assign(x, *params)
        params = maximize(x, z)
    return params
```
:::

## When to stop?

```{python}
#| echo: true
def em(x, eps=1e-5):
    params = maximize(x, x > 5)

    old_llik = -np.inf
    llik = log_likelihood(x, *params)

    for _ in range(100):
        z = assign(x, *params)
        params = maximize(x, z)
        new_llik = llik

        if new_llik < old_llik + eps:
            break
    return params
```